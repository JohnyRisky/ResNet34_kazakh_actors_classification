{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cc94e71-c851-4826-bfa0-cbb469e7d051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as utils\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms.v2 as v2\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f4be75-d5c8-457a-aa1e-d7033f25973d",
   "metadata": {},
   "source": [
    "### Подготовка модели ResNet34 и замена последнего и предпосл слоев нейросети под наши цели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2de67d3e-4c6a-4313-a26b-64f44691f0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = \"ActorsDataset\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "resnet34_weights = models.ResNet34_Weights.DEFAULT\n",
    "resnet34_transforms = resnet34_weights.transforms()\n",
    "\n",
    "model = models.resnet34(weights=resnet34_weights).to(device)\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(512, 128),\n",
    "    nn.BatchNorm1d(128),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(128, 7) # Корректируем посл слой под наши цели\n",
    ")\n",
    "\n",
    "for param in model.parameters(): # вся модель не будет обучаться\n",
    "    param.requires_grad = False\n",
    "\n",
    "#for param in model.layer4.parameters(): # оптимизируем только последний и предпосл слои\n",
    "#    param.requires_grad = True\n",
    "\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de12cc5-768f-4b8e-b50d-ca78eb63eff3",
   "metadata": {},
   "source": [
    "### Используйте файл actors_images_crawler.ipynb чтобы скачать изображения актеров и создать требуемую структуру\n",
    "### Далее создаем объекты классов Dataset и Dataloader\n",
    "### Оптимизатор и функция потерь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ad61c0ed-5ebb-4803-bd8b-7efdddfbd22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorsDataset(utils.Dataset):\n",
    "    def __init__(self, path: str, train: bool = True, transforms=None):\n",
    "        self.path = os.path.join(path, \"train\" if train else \"test\")\n",
    "        self.transforms = transforms\n",
    "\n",
    "        with open(\"format.json\", \"r\", encoding=\"utf-8\") as fp:\n",
    "            self.schema = json.load(fp)\n",
    "\n",
    "        self.images = []\n",
    "        self.len_images = 0\n",
    "\n",
    "        for folder, target in self.schema.items():\n",
    "            actor_path = os.path.join(self.path, folder)\n",
    "            actor_images = os.listdir(actor_path)\n",
    "            self.len_images += len(actor_images)\n",
    "            self.images.extend(\n",
    "                (os.path.join(actor_path, img), target) for img in actor_images\n",
    "            )\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        path, target = self.images[item]\n",
    "        \n",
    "        image = Image.open(path).convert(\"RGB\")\n",
    "    \n",
    "        if self.transforms:\n",
    "            image = self.transforms(image).to(device)\n",
    "    \n",
    "        return image, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len_images\n",
    "\n",
    "\n",
    "actors_train_dataset = ActorsDataset(dataset_folder, train=True, transforms=resnet34_transforms)\n",
    "actors_train_dataloader = utils.DataLoader(actors_train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "test_dataset = ActorsDataset(dataset_folder, train=False, transforms=resnet34_transforms)\n",
    "test_dataloader = utils.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    #list(model.fc.parameters()) + list(model.layer4.parameters()),\n",
    "    model.fc.parameters(),\n",
    "    lr=0.001\n",
    "    #weight_decay=0.0001\n",
    ")\n",
    "loss_func = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a27de6-6504-4c44-bb9d-dab14aac7031",
   "metadata": {},
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3f8f1493-917c-4c00-bece-968cac04227a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.1172\n",
      "Epoch 2/10, Loss: 0.5057\n",
      "Epoch 3/10, Loss: 0.3338\n",
      "Epoch 4/10, Loss: 0.2321\n",
      "Epoch 5/10, Loss: 0.1570\n",
      "Epoch 6/10, Loss: 0.1466\n",
      "Epoch 7/10, Loss: 0.1253\n",
      "Epoch 8/10, Loss: 0.1058\n",
      "Epoch 9/10, Loss: 0.1023\n",
      "Epoch 10/10, Loss: 0.0914\n"
     ]
    }
   ],
   "source": [
    "#best_result = float(\"inf\")\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for x_train, y_train in actors_train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        predict = model(x_train)\n",
    "        loss = loss_func(predict, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    avg_loss = epoch_loss / len(actors_train_dataloader)\n",
    "\n",
    "    # if avg_loss < best_result: # сохраняем параметры модели и оптимизатора если рещультаты стали лучше\n",
    "    #     best_result = avg_loss\n",
    "    #     torch.save({\n",
    "    #         'epoch': epoch + 1,\n",
    "    #         'model_state_dict': model.state_dict(),\n",
    "    #         'optimizer_state_dict': optimizer.state_dict(),\n",
    "    #         'loss': avg_loss\n",
    "    #     }, f\"{epoch + 1}_result.tar\")\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d1dcb9-f502-4691-8200-605ca81395b7",
   "metadata": {},
   "source": [
    "### Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "82922839-e0df-40b6-8aa2-68e81a286c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Loss: 1.2716\n",
      "Test Accuracy: 0.6511\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "total = 0\n",
    "correct = 0\n",
    "test_loss = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_test, y_test in test_dataloader:\n",
    "        predict = model(x_test)\n",
    "        loss = loss_func(predict, y_test)\n",
    "        test_loss += loss.item()\n",
    "        preds = torch.argmax(predict, dim=1)\n",
    "        correct += (preds == y_test).sum().item()\n",
    "        total += y_test.size(0)\n",
    "\n",
    "print(f\"\\nTest Loss: {test_loss / len(test_dataloader):.4f}\")\n",
    "print(f\"Test Accuracy: {correct / total:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c11569-8a2f-47b8-b28b-f992ada41c75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
